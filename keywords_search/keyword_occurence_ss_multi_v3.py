import requests
import pandas as pd
import time
import random
import datetime
from tqdm import tqdm

# ğŸ“Œ Fonction de requÃªte API Semantic Scholar
def get_publication_count(keyword, year, max_retries=5):
    url = "https://api.semanticscholar.org/graph/v1/paper/search"
    params = {
        "query": keyword,
        "year": year,
        "limit": 1,  # On ne veut que le nombre total
        "fields": "title"
    }

    for attempt in range(max_retries):
        try:
            response = requests.get(url, params=params)
            if response.status_code == 200:
                return response.json().get("total", 0)
            elif response.status_code == 429:
                wait = 5 + attempt * 2
                print(f"âš ï¸  Trop de requÃªtes (429). Pause de {wait} secondes...")
                time.sleep(wait)
            else:
                print(f"âŒ Erreur {response.status_code} pour {keyword} ({year})")
                return None
        except Exception as e:
            print(f"â›” Erreur : {e}")
            time.sleep(5)
    return None

# ğŸ” Analyse de tous les mots-clÃ©s
def analyze_keywords(keywords, start_year, end_year):
    global_results = []

    print("\nğŸ“Š Lancement de lâ€™analyse pour chaque mot-clÃ©...\n")

    for keyword in keywords:
        print(f"ğŸ” Mot-clÃ© : '{keyword}'")
        keyword_results = []

        for year in tqdm(range(start_year, end_year + 1)):
            count = get_publication_count(keyword, year)
            keyword_results.append({
                "Mot-clÃ©": keyword,
                "AnnÃ©e": year,
                "Occurrences": count
            })
            time.sleep(random.uniform(1.0, 2.5))

        # ğŸ’¾ Sauvegarde individuelle
        df_indiv = pd.DataFrame(keyword_results)
        filename = f"semantic_keyword_{keyword.replace(' ', '_')}_{start_year}_{end_year}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        df_indiv.to_excel(filename, index=False)
        print(f"âœ… RÃ©sultats sauvegardÃ©s dans : {filename}\n")

        global_results.extend(keyword_results)

    return pd.DataFrame(global_results)

# ğŸ” CrÃ©ation du tableau croisÃ©
def create_pivot_table(df, output_filename="semantic_summary.xlsx"):
    pivot = df.pivot_table(index="Mot-clÃ©", columns="AnnÃ©e", values="Occurrences", fill_value=0)
    pivot.to_excel(output_filename)
    print(f"\nğŸ“ˆ Tableau comparatif sauvegardÃ© dans : {output_filename}")

# ğŸš€ Programme principal
if __name__ == "__main__":
    print("\nğŸ§  Analyse multi-mots-clÃ©s avec lâ€™API Semantic Scholar")
    print("ğŸ¯ Objectif : Voir l'Ã©volution annuelle du nombre de publications contenant chaque mot-clÃ©.")
    print("â„¹ï¸  Les chiffres correspondent aux **nouvelles publications** de chaque annÃ©e.\n")

    # Demander les paramÃ¨tres
    start_year = int(input("ğŸ“… AnnÃ©e de dÃ©but : "))
    end_year = int(input("ğŸ“… AnnÃ©e de fin   : "))

    # Liste de mots-clÃ©s manuelle
    raw_keywords = input("ğŸ“ Entrez les mots-clÃ©s sÃ©parÃ©s par des virgules :\nğŸ‘‰ ")
    keywords = [kw.strip() for kw in raw_keywords.split(",") if kw.strip()]

    # Lancer lâ€™analyse
    df_all = analyze_keywords(keywords, start_year, end_year)

    # CrÃ©er le tableau comparatif
    create_pivot_table(df_all)
